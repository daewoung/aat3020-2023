{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020-2023/blob/main/notebooks/4_Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c87a7a",
      "metadata": {
        "id": "80c87a7a"
      },
      "source": [
        "# Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install HuggingFace\n",
        "!pip install transformers tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6OfzjCACzNM",
        "outputId": "0d6806bb-774c-43f9-857c-5c396a46df0c"
      },
      "id": "Y6OfzjCACzNM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "518b10da",
      "metadata": {
        "id": "518b10da",
        "outputId": "20f69b3d-7d3a-4a6f-9a2a-e85fa02b86bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GMFWREWBVcD5vJdwNFadHmzVStclcyKf\n",
            "To: /content/nia-aihub-korean-english-txt.zip\n",
            "100% 449M/449M [00:04<00:00, 98.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Download dataset (originally from NIA AI-Hub)\n",
        "'''\n",
        "\n",
        "# !gdown 1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g\n",
        "# !unzip -q nia-aihub-korean-english.zip\n",
        "\n",
        "!gdown 1GMFWREWBVcD5vJdwNFadHmzVStclcyKf\n",
        "!unzip -q nia-aihub-korean-english-txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "dWNSKjhdJ1jM"
      },
      "id": "dWNSKjhdJ1jM",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ca202b9d",
      "metadata": {
        "scrolled": true,
        "id": "ca202b9d",
        "outputId": "e415e08d-0eca-4d52-ecc3-414e60d7cff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-fce48fd2435d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "# You don't have to run this\n",
        "'''\n",
        "dataset_dir = Path('nia_korean_english')\n",
        "data_list = sorted(list(dataset_dir.glob('*.xlsx')))\n",
        "for path in data_list:\n",
        "  df = pd.read_excel(path)\n",
        "  kor_text_path = path.parent / (path.stem+'_kor.txt') \n",
        "  eng_text_path = path.parent / (path.stem+'_eng.txt') \n",
        "  with open(kor_text_path, 'w', encoding='utf8') as f:\n",
        "      f.write('\\n'.join(df['원문']))\n",
        "  with open(eng_text_path, 'w', encoding='utf8') as f:\n",
        "      f.write('\\n'.join(df['번역문']))\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1fbc2c73",
      "metadata": {
        "id": "1fbc2c73",
        "outputId": "f948c9f0-78dd-4ce2-b669-c2ed92bbc6e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('nia_korean_english/1_구어체(1).xlsx'),\n",
              " PosixPath('nia_korean_english/1_구어체(2).xlsx'),\n",
              " PosixPath('nia_korean_english/2_대화체.xlsx'),\n",
              " PosixPath('nia_korean_english/3_문어체_뉴스(1)_200226.xlsx'),\n",
              " PosixPath('nia_korean_english/3_문어체_뉴스(2).xlsx'),\n",
              " PosixPath('nia_korean_english/3_문어체_뉴스(3).xlsx'),\n",
              " PosixPath('nia_korean_english/3_문어체_뉴스(4).xlsx'),\n",
              " PosixPath('nia_korean_english/4_문어체_한국문화.xlsx'),\n",
              " PosixPath('nia_korean_english/5_문어체_조례.xlsx'),\n",
              " PosixPath('nia_korean_english/6_문어체_지자체웹사이트.xlsx')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "dataset_dir = Path('nia_korean_english')\n",
        "data_list = sorted(list(dataset_dir.glob('*.xlsx')))\n",
        "\n",
        "data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6c767468",
      "metadata": {
        "id": "6c767468",
        "outputId": "be64a757-971e-49f5-e0eb-458aeaedaf6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-730a28c173f9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-730a28c173f9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \"\"\"\n\u001b[1;32m    556\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openpyxl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mopenpyxl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         return load_workbook(\n\u001b[0m\u001b[1;32m    569\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(filename, read_only, keep_vba, data_only, keep_links)\u001b[0m\n\u001b[1;32m    315\u001b[0m     reader = ExcelReader(filename, read_only, keep_vba,\n\u001b[1;32m    316\u001b[0m                         data_only, keep_links)\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_manifest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36mread_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mstrings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPartName\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_string_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/reader/strings.py\u001b[0m in \u001b[0;36mread_string_table\u001b[0;34m(xml_source)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTRING_TAG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x005F_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/descriptors/serialisable.py\u001b[0m in \u001b[0;36mfrom_tree\u001b[0;34m(cls, node)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/cell/text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, t, r, rPh, phoneticPr)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrPh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrPh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoneticPr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphoneticPr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/descriptors/sequence.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, instance, seq)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Value must be a sequence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndexedList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/descriptors/sequence.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Value must be a sequence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndexedList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dfs = [pd.read_excel(path) for path in data_list[:1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9f316f",
      "metadata": {
        "id": "2e9f316f"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(dfs, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"nia_korean_english/1_구어체(1)_kor.txt\", 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(df['원문']))\n"
      ],
      "metadata": {
        "id": "gKyXWsJjjrLR"
      },
      "id": "gKyXWsJjjrLR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8b8786",
      "metadata": {
        "id": "ff8b8786"
      },
      "outputs": [],
      "source": [
        "df['원문'][10000:10050], df['번역문'][10000:10050]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df6e584",
      "metadata": {
        "id": "3df6e584"
      },
      "source": [
        "## Huggingface Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6c6f1769",
      "metadata": {
        "id": "6c6f1769",
        "outputId": "f1f0dfad-d93b-482d-8c92-d46bc4177580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hugging_eng_32000/vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
        "\n",
        "num_files = 2\n",
        "\n",
        "corpus_file   =  [str(path.parent / (path.stem + '_kor.txt')) for path in data_list[:num_files]]\n",
        "# output_dir   = Path('hugging_kor_%d'%(vocab_size))\n",
        "en_corpus_file   =  [str(path.parent / (path.stem + '_eng.txt')) for path in data_list[:num_files]]\n",
        "# output_dir   = Path('hugging_eng_%d'%(vocab_size))\n",
        "\n",
        "vocab_size    = 32000  # Number of maximum size of the vocabulary\n",
        "limit_alphabet= 6000   \n",
        "output_dir    = Path('hugging_kor_%d'%(vocab_size))\n",
        "en_output_dir = Path('hugging_eng_%d'%(vocab_size))\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "en_output_dir.mkdir(exist_ok=True)\n",
        "min_frequency = 5 \n",
        "\n",
        "tokenizer.train(files=corpus_file,\n",
        "               vocab_size=vocab_size,\n",
        "               min_frequency=min_frequency,\n",
        "               limit_alphabet=limit_alphabet, \n",
        "               show_progress=True)\n",
        "\n",
        "tokenizer.save_model(str(output_dir))\n",
        "\n",
        "en_tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
        "en_tokenizer.train(files=en_corpus_file,\n",
        "                vocab_size=vocab_size,\n",
        "                min_frequency=min_frequency,\n",
        "                limit_alphabet=limit_alphabet,\n",
        "                show_progress=True)\n",
        "en_tokenizer.save_model(str(en_output_dir))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "410eb97a",
      "metadata": {
        "scrolled": true,
        "id": "410eb97a",
        "outputId": "6598a1c1-1356-447d-975b-6d92303aaba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"이는 경기연구원이 발간한 <경기도 어린이 등·하굣길 교통안전 증진방안>에 담긴 내용으로, 보고서는 지역·원인별 어린이 교통사고를 분석하여 교통안전을 위한 방안을 제안하고 있다.\"\n",
            "[CLS] \" 이는 경기연구원이 발간한 < 경기도 어린이 등 · 하굣길 교통안전 증진방안 > 에 담긴 내용으로, 보고서는 지역 · 원인별 어린이 교통사고를 분석하여 교통안전을 위한 방안을 제안하고 있다. \" [SEP]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer_src = BertTokenizerFast.from_pretrained('hugging_kor_32000',\n",
        "                                                       strip_accents=False,\n",
        "                                                       lowercase=False) \n",
        "tokenizer_tgt = BertTokenizerFast.from_pretrained('hugging_eng_32000',\n",
        "                                                       strip_accents=False,\n",
        "                                                       lowercase=False) \n",
        "\n",
        "tokenized_data = tokenizer_src(df['원문'].iloc[10])\n",
        "print(df['원문'].iloc[10])\n",
        "print(tokenizer_src.decode(tokenized_data['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data['input_ids']"
      ],
      "metadata": {
        "id": "q9GJ7cifk5tg"
      },
      "id": "q9GJ7cifk5tg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "340f55c0",
      "metadata": {
        "id": "340f55c0",
        "outputId": "ccdfb5b5-0263-48d9-a8b6-a7d54ad9e731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3715, 1079, 2604, 12638, 12008, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tokenized_ids = tokenizer_src(\"나는 서강대학교에 다닙니다\")['input_ids']\n",
        "tokenized_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5b3ea831",
      "metadata": {
        "id": "5b3ea831",
        "outputId": "ae85eb77-670f-4df2-8d3b-4ab3ad5695e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] 나는 서강대학교에 다닙니다 [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "tokenizer_src.decode(tokenized_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26964dcb",
      "metadata": {
        "id": "26964dcb"
      },
      "source": [
        "## Divide Train / Validate/ Test Set\n",
        "- using `np.random.choice`\n",
        "    - To always get the same random shuffling result, you have to use `np.random.seed()`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "B2zJgvXPlh95",
        "outputId": "33f24480-2a88-418e-d95d-b01f5b6050d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "id": "B2zJgvXPlh95",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ID     지자체                                                 원문  \\\n",
              "0       261811     경기도  \"경기도가 말산업 육성을 위해 총예산 245,193천원으로 2013년 경기도 용인시...   \n",
              "1       409852     경기도  \"경기도가 주최하고 경기FTA활용지원센터와 코트라가 주관한 이번 시장개척단은 지난 ...   \n",
              "2       352671     경기도  \"경기도가 주최하고 경기도비정규직지원센터가 주관한 이번 교육은 공공 부문이 직·간접...   \n",
              "3       308191     경기도  \"경기도가 주최하고 사단법인 한국장애인복지시설협회 경기도협회(대표자:정권)에서 주관...   \n",
              "4       185424     경기도  \"경기도가 주최하고 인구보건복지협회 경기지회, 아이낳기좋은세상 경기운동본부가 주관하...   \n",
              "...        ...     ...                                                ...   \n",
              "100082   73961  서울시 중구  힐튼호텔 건너편에서 회현동주민센터로 내려가는 길에는 칙칙한 회색의 석축옹벽이 이어져...   \n",
              "100083  462950     경기도  힘든 분들이 많이 계시지만 조금이나마 어렵지 않도록 도움이 될 수 있도록 저희가 최...   \n",
              "100084  333006     경기도  힘든 역사 속에서 대한민국을 불과 50여년 만에 빛나는 나라로 만들고 업적을 만들 ...   \n",
              "100085  454399     경기도  힘든 일을 하는 데는 무엇보다 정부가 큰 관심을 갖고 있다는 자부심을 갖도록 해야 한다.   \n",
              "100086  507679     경기도  힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...   \n",
              "\n",
              "                                                      번역문  \n",
              "0       \"The Gyeonggi provincial government announced ...  \n",
              "1       \"Organized by Gyeonggi provincial government a...  \n",
              "2       \"Organized by Gyeonggi provincial government a...  \n",
              "3       \"Organized by Gyeonggi provincial government a...  \n",
              "4       \"Hosted by Gyeonggi provincial government, org...  \n",
              "...                                                   ...  \n",
              "100082  Across from the Hilton Hotel, the path to Hoeh...  \n",
              "100083  There are a lot of people who are having a har...  \n",
              "100084  It was possible to make the Republic of Korea ...  \n",
              "100085  As for doing hard work, most of all, they shou...  \n",
              "100086  I would like to thank all the leaders here for...  \n",
              "\n",
              "[100087 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d659cf52-06c5-4062-a100-2c32cbe09de2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>지자체</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>261811</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 말산업 육성을 위해 총예산 245,193천원으로 2013년 경기도 용인시...</td>\n",
              "      <td>\"The Gyeonggi provincial government announced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>409852</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 경기FTA활용지원센터와 코트라가 주관한 이번 시장개척단은 지난 ...</td>\n",
              "      <td>\"Organized by Gyeonggi provincial government a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>352671</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 경기도비정규직지원센터가 주관한 이번 교육은 공공 부문이 직·간접...</td>\n",
              "      <td>\"Organized by Gyeonggi provincial government a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>308191</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 사단법인 한국장애인복지시설협회 경기도협회(대표자:정권)에서 주관...</td>\n",
              "      <td>\"Organized by Gyeonggi provincial government a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>185424</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 인구보건복지협회 경기지회, 아이낳기좋은세상 경기운동본부가 주관하...</td>\n",
              "      <td>\"Hosted by Gyeonggi provincial government, org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100082</th>\n",
              "      <td>73961</td>\n",
              "      <td>서울시 중구</td>\n",
              "      <td>힐튼호텔 건너편에서 회현동주민센터로 내려가는 길에는 칙칙한 회색의 석축옹벽이 이어져...</td>\n",
              "      <td>Across from the Hilton Hotel, the path to Hoeh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100083</th>\n",
              "      <td>462950</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘든 분들이 많이 계시지만 조금이나마 어렵지 않도록 도움이 될 수 있도록 저희가 최...</td>\n",
              "      <td>There are a lot of people who are having a har...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100084</th>\n",
              "      <td>333006</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘든 역사 속에서 대한민국을 불과 50여년 만에 빛나는 나라로 만들고 업적을 만들 ...</td>\n",
              "      <td>It was possible to make the Republic of Korea ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100085</th>\n",
              "      <td>454399</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘든 일을 하는 데는 무엇보다 정부가 큰 관심을 갖고 있다는 자부심을 갖도록 해야 한다.</td>\n",
              "      <td>As for doing hard work, most of all, they shou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100086</th>\n",
              "      <td>507679</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...</td>\n",
              "      <td>I would like to thank all the leaders here for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100087 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d659cf52-06c5-4062-a100-2c32cbe09de2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d659cf52-06c5-4062-a100-2c32cbe09de2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d659cf52-06c5-4062-a100-2c32cbe09de2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "boOZlijtlpgv",
        "outputId": "9ce04f9d-ee41-43a0-9463-c1d444496e01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "boOZlijtlpgv",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100087"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[-1]"
      ],
      "metadata": {
        "id": "NdDy0EHNlv60",
        "outputId": "3180be90-6287-4e22-b28f-887e43166aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NdDy0EHNlv60",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                                                507679\n",
              "지자체                                                  경기도\n",
              "원문     힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...\n",
              "번역문    I would like to thank all the leaders here for...\n",
              "Name: 100086, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/nia_korean_english/1_구어체(1).xlsx\")"
      ],
      "metadata": {
        "id": "AGA1i06oMD1N"
      },
      "id": "AGA1i06oMD1N",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ba4a138a",
      "metadata": {
        "id": "ba4a138a"
      },
      "source": [
        "## Define Dataset\n",
        "- Each datasample has to return source sentence and target sentence\n",
        "- You need a Tokenizer to get the tokenized result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b088f662",
      "metadata": {
        "id": "b088f662",
        "outputId": "147be13b-5b25-4793-d55d-a7fc9377b11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    2,    10,    65, 24704,  7560, 26729,  2320,  5837,  8818,    10,\n",
            "         1386, 12898,  2044,  4757,  4730,  6035,  1902,  1127,  3727,  5483,\n",
            "         2241, 22155,    15,     3])\n",
            "tensor([    2, 11899, 12755,    10,   354,    68, 12755,  2319,   380,  4529,\n",
            "          342,   335,  1335,  1336,  3916,   348,   329, 11899,    17])\n",
            "tensor([11899, 12755,    10,   354,    68, 12755,  2319,   380,  4529,   342,\n",
            "          335,  1335,  1336,  3916,   348,   329, 11899,    17,     3])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class Dataset:\n",
        "  def __init__(self, df, src_tokenizer, tgt_tokenizer):\n",
        "    self.data = df\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    selected_row = self.data.iloc[idx]\n",
        "    source = selected_row['원문']\n",
        "    target = selected_row['번역문']\n",
        "\n",
        "    source_enc = self.src_tokenizer(source)['input_ids']\n",
        "    target_enc = self.tgt_tokenizer(target)['input_ids']\n",
        "\n",
        "    return torch.LongTensor(source_enc), torch.LongTensor(target_enc[:-1]), torch.LongTensor(target_enc[1:])\n",
        "  \n",
        "dataset = Dataset(df, tokenizer_src, tokenizer_tgt)\n",
        "\n",
        "source, target, shifted_target = dataset[0]\n",
        "print(source)\n",
        "print(target)\n",
        "print(shifted_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset\n",
        "- using ``torch.utils.data.random_split(dataset)``"
      ],
      "metadata": {
        "id": "kMaE7cK2EurA"
      },
      "id": "kMaE7cK2EurA"
    },
    {
      "cell_type": "code",
      "source": [
        "num_data = len(dataset)\n",
        "# num_data\n",
        "num_train = int(num_data * 0.8)\n",
        "num_valid = int(num_data * 0.1)\n",
        "# num_test = int(num_data * 0.1)\n",
        "num_test = num_data - (num_train + num_valid)\n",
        "\n",
        "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [num_train, num_valid, num_test])\n",
        "print(len(train_set), len(valid_set), len(test_set))"
      ],
      "metadata": {
        "id": "Lb8fmwGbEhU1",
        "outputId": "d189ec91-804c-4dad-e631-02cfeaca02b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Lb8fmwGbEhU1",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160000 20000 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "76933a49",
      "metadata": {
        "id": "76933a49"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "batch"
      ],
      "metadata": {
        "id": "oTmu4Yy_N7vt",
        "outputId": "26fc0c48-97db-4dad-883f-f1e123e98bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oTmu4Yy_N7vt",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[   2,  404, 5499,  950, 1398, 3746,   15,    3]]),\n",
              " tensor([[   2,   76,   10,  746,  810,  906,  335,  412, 2590,   17]]),\n",
              " tensor([[  76,   10,  746,  810,  906,  335,  412, 2590,   17,    3]])]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a9f0ec",
      "metadata": {
        "id": "f4a9f0ec"
      },
      "source": [
        "## Define Collate function\n",
        "- After implementing Dataset, we have to declare DataLoader that groups several training samples as a single batch\n",
        "- However, we cannot batchify the melodies in straightforward way, because the length of each melody is different\n",
        "- In this problem, you will learn about how to handle sequences of different length as a batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "456ff9f2",
      "metadata": {
        "id": "456ff9f2"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "This cell will make error, because the length of each sample is different to each other\n",
        "'''\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=8)\n",
        "batch = next(iter(train_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc533f7",
      "metadata": {
        "id": "afc533f7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "To handle that problem, you have to make your collate function \n",
        "'''\n",
        "def your_collate_function(raw_batch):\n",
        "  '''\n",
        "  You can make your own function to handle the batch\n",
        "  '''\n",
        "  \n",
        "  return raw_batch[0] # This returns the first melody of each batch. So it will avoid the error, but it doesn't do proper batchifying\n",
        "\n",
        "batch_size = 8\n",
        "raw_batch = [train_set[i] for i in range(batch_size)] # This is the input for the collate function\n",
        "batch = your_collate_function(raw_batch)\n",
        "\n",
        "'''\n",
        "This is what the 'collate_fn' does in DataLoader\n",
        "'''\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn=your_collate_function)\n",
        "batch_by_loader = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22db0716",
      "metadata": {
        "id": "22db0716"
      },
      "source": [
        "#### Pad Sequence and Pack Sequence\n",
        "In PyTorch, there are two ways to batchify a group of sequence with different length.\n",
        "- `torch.nn.utils.rnn.pad_sequence`\n",
        "    - This function takes list of tensors with different length and return padded sequence\n",
        "    - Padding is adding some constant number as a PAD token to match the length of short sequence to the maximum length\n",
        "        - e.g. If there are sequence of length (3,7,4), we can add 4 zeros to sequence with length 3, 3 zeros to sequence with length 4 to make them length 7\n",
        "    - In default, we use 0 for padding (zero padding)\n",
        "    - The result \n",
        "- `torch.nn.utils.rnn.pack_sequence`\n",
        "    - pad_sequence "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c8cce88",
      "metadata": {
        "id": "1c8cce88"
      },
      "source": [
        "Cells below show the example of `pad_sequence`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe229f85",
      "metadata": {
        "id": "fe229f85"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, PackedSequence\n",
        "short = torch.arange(3, -1, -1).float() # [3, 2, 1, 0]\n",
        "long = torch.arange(27,19, -1).float()\n",
        "middle = torch.arange(15,9, -1).float()\n",
        "\n",
        "pad_sequence([short, long, middle], batch_first=False)  # T x N "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2a0920",
      "metadata": {
        "id": "0b2a0920"
      },
      "outputs": [],
      "source": [
        "# Default value of batch_first in pad_sequence is False.\n",
        "# So you have to always be careful not to miss batch_first=True in pad_sequence, if you use batch_first=True for your RNN layer.\n",
        "pad_sequence([short, long, middle], batch_first=True)  # N x T "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fb5e0dd",
      "metadata": {
        "id": "4fb5e0dd"
      },
      "source": [
        "1) However, the problem is that you can't figure out whether the 0 at the end of each sequence is a padded one, or was included in the original sequence\n",
        "- e.g. `[2, 3, 4, 3, 0]` becomes `[ 2,  3,  4,  5,  0,  0,  0]`. Now we don't know how many zeros were added for padding\n",
        "\n",
        "2) Also, if you run RNN for this padded sequence, RNN will calculate for the padded part also.\n",
        "- RNN doesn't know whether it is padded data, or existing data\n",
        "- This makes computation slower\n",
        "\n",
        "3) If you want to use bi-directional, which also reads the sequence from backward, paddings can make the result different.\n",
        "\n",
        "To solve this issue, we use PackedSequence, by using `pack_sequence`/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69086d43",
      "metadata": {
        "id": "69086d43"
      },
      "outputs": [],
      "source": [
        "packed_sequence = pack_sequence([short, long, middle], enforce_sorted=False)\n",
        "packed_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd50747",
      "metadata": {
        "id": "4cd50747"
      },
      "source": [
        "`PackedSequence` has `data` and `batch_sizes`\n",
        "- `data` contains the flattened value of given batch\n",
        "    - To optimize the computation, the sequences have to be sorted by descending of length\n",
        "- `batch_sizes` represents how many valid batch sample exists for each time step\n",
        "    - `[3, 3, 3, 2, 2, 1, 1]` means that there are 3 sequences for first three time steps, and then 2 sequences for next two steps, and then only 1 sequence for next two steps.\n",
        "- `sorted_indices` shows how the sorted sequences can be converted to original order.\n",
        "    - `[1,2,0]` means that \n",
        "        - the 0th sequence in the sorted sequences (the longest one) was indexed as 1 in the original input batch\n",
        "        - the 1st sequence in the sorted sequences (`middle`) was indexed as 2 in the original input batch\n",
        "        - the 2nd sequence in the sorted sequences (`short`) was index as 0 in the original input batch\n",
        "- `unsorted_indices` shows how the original sequences are sorted.\n",
        "    - `[2,0,1]` means that\n",
        "        - the 0th sequence in the original input was sorted as 2nd in the sorted sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0500f200",
      "metadata": {
        "id": "0500f200"
      },
      "outputs": [],
      "source": [
        "rnn_layer = nn.GRU(1, 1)\n",
        "packed_sequence = pack_sequence([short.unsqueeze(1), long.unsqueeze(1), middle.unsqueeze(1)], enforce_sorted=False)\n",
        "out, last_hidden = rnn_layer(packed_sequence)\n",
        "\n",
        "print(f\"Type of output of RNN for PackedSequence: {type(out)}\")\n",
        "print(f\"Type of last_hidden of RNN for PackedSequence: {type(last_hidden)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f2e3e44",
      "metadata": {
        "id": "8f2e3e44"
      },
      "source": [
        "- RNN or its family of PyTorch can automatically handle `PackedSequence`\n",
        "- However, other layers like `nn.Embedding` or `nn.Linear` cannot take `PackedSequence` as its input\n",
        "- There are two ways to feed `PackedSequence` to these layers\n",
        "    - First, convert PackedSequence to ordinary torch.Tensor by `torch.nn.utils.rnn.pad_packed_sequence`\n",
        "        - This will convert PackedSequence to a tensor of sequneces with same length but different padding\n",
        "    - The other way is to feed only PackedSequence.data, and then declaring new PackedSequence with the output as `data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08620c8",
      "metadata": {
        "id": "b08620c8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This will make error, because other layers cannot handle PackedSequence\n",
        "'''\n",
        "test_linear_layer = nn.Linear(in_features=1, out_features=2)\n",
        "test_linear_layer(packed_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9efa09",
      "metadata": {
        "id": "ac9efa09"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "One way to to this is using torch.nn.utils.rnn.pad_packed_sequence to convert PackedSequence to ordinary tensor\n",
        "'''\n",
        "\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "padded_sequence, batch_lengths = pad_packed_sequence(packed_sequence)\n",
        "print(f'The padded sequence generated from packed sequence (squeezed for printing): \\n {padded_sequence.squeeze()}')\n",
        "print(f'\"pad_packed_sequence\" also returns \"batch_lengths\", to clarify the original length before the padding: \\n {batch_lengths}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e302fe4",
      "metadata": {
        "id": "8e302fe4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Now you can feed padded sequence to linear layer.\n",
        "'''\n",
        "\n",
        "linear_output = test_linear_layer(padded_sequence)\n",
        "print(f\"Output of feeding padded_sequence to a linear layer: {linear_output}\")\n",
        "print(\"Caution that it returns non-zero values for timestep with zero padding, because linear layer has a bias\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c0e150",
      "metadata": {
        "id": "b1c0e150"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You can make the output as a PackedSequence, by using torch.nn.utils.rnn.pack_padded_sequence\n",
        "'''\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "re_packed_sequence = pack_padded_sequence(linear_output, batch_lengths, enforce_sorted=False)\n",
        "re_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22117c41",
      "metadata": {
        "id": "22117c41"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Another way to do it is using PackedSequence.data\n",
        "'''\n",
        "\n",
        "linear_out_pack = test_linear_layer(packed_sequence.data)\n",
        "packed_sequence_after_linear = PackedSequence(linear_out_pack, packed_sequence.batch_sizes, packed_sequence.sorted_indices, packed_sequence.unsorted_indices)\n",
        "packed_sequence_after_linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81dd119c",
      "metadata": {
        "id": "81dd119c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "357c61f4",
      "metadata": {
        "id": "357c61f4"
      },
      "source": [
        "## Define Model\n",
        "![image](https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/seq2seq.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "0af0ca29",
      "metadata": {
        "id": "0af0ca29",
        "outputId": "c99b310d-221e-4354-ca9c-c0d2c770b233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 30679]),\n",
              " tensor([[[3.7831e-05, 3.5256e-05, 3.0584e-05,  ..., 3.3500e-05,\n",
              "           2.4337e-05, 2.7672e-05],\n",
              "          [3.7944e-05, 3.5618e-05, 2.9544e-05,  ..., 3.2880e-05,\n",
              "           2.4043e-05, 2.8977e-05],\n",
              "          [3.8737e-05, 3.6563e-05, 3.0205e-05,  ..., 3.1515e-05,\n",
              "           2.4715e-05, 2.8846e-05],\n",
              "          ...,\n",
              "          [3.4987e-05, 3.2082e-05, 3.2948e-05,  ..., 3.7204e-05,\n",
              "           2.8179e-05, 3.4997e-05],\n",
              "          [3.4883e-05, 3.2334e-05, 3.5071e-05,  ..., 3.8582e-05,\n",
              "           3.0073e-05, 3.6565e-05],\n",
              "          [3.5365e-05, 3.1588e-05, 3.2468e-05,  ..., 3.8394e-05,\n",
              "           2.9759e-05, 3.5212e-05]]], grad_fn=<SoftmaxBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "class Seq2seq(nn.Module):\n",
        "  def __init__(self, enc_vocab, dec_vocab, hidden_size):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(enc_vocab, hidden_size)\n",
        "    self.decoder = Decoder(dec_vocab, hidden_size)\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    enc_out = self.encoder(src)\n",
        "    dec_out = self.decoder(tgt, enc_out)\n",
        "    return dec_out \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_vocab, hidden_size):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(num_vocab, hidden_size)\n",
        "    self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=2)\n",
        "    # batch_first True: it takes (Num_samples_in_batch, num_timesteps, num_dim)\n",
        "    # batch_first False: it takes (num_timesteps, Num_samples_in_batch, num_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    emb = self.emb(x)\n",
        "    out, last_hidden = self.rnn(emb)\n",
        "    return last_hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, num_vocab, hidden_size):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(num_vocab, hidden_size)\n",
        "    self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=2)\n",
        "    self.proj = nn.Linear(hidden_size, num_vocab)\n",
        "\n",
        "\n",
        "  def forward(self, x, enc_output):\n",
        "    emb = self.emb(x)\n",
        "    out, last_hidden = self.rnn(emb, enc_output)\n",
        "    logit = self.proj(out)\n",
        "    return logit\n",
        "\n",
        "hidden_size = 64\n",
        "model = Seq2seq(tokenizer_src.vocab_size, tokenizer_tgt.vocab_size, hidden_size)\n",
        "encoder = Encoder(tokenizer_src.vocab_size, hidden_size)\n",
        "decoder = Decoder(tokenizer_tgt.vocab_size, hidden_size)\n",
        "\n",
        "src, tgt, shifted_tgt = batch\n",
        "\n",
        "enc_out = encoder(src)\n",
        "dec_out = decoder(tgt, enc_out)\n",
        "\n",
        "logit = model(src, tgt)\n",
        "logit.shape, logit.softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit.shape, shifted_tgt.shape, shifted_tgt"
      ],
      "metadata": {
        "id": "WMGUwt10Whf5",
        "outputId": "53bf8946-490b-41cd-ca60-8eaa32b28fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WMGUwt10Whf5",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 30679]),\n",
              " torch.Size([1, 10]),\n",
              " tensor([[  76,   10,  746,  810,  906,  335,  412, 2590,   17,    3]]))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nll_loss(pred, target, eps=1e-8):\n",
        "  if pred.ndim == 3:\n",
        "    pred = pred.flatten(0, 1)\n",
        "  if target.ndim == 2:\n",
        "    target = target.flatten(0, 1)\n",
        "  assert pred.ndim == 2\n",
        "  assert target.ndim == 1\n",
        "\n",
        "  \n",
        "  return -torch.log(pred[torch.arange(len(target)), target] + eps).mean()\n",
        "\n",
        "loss = nll_loss(logit.softmax(dim=-1), shifted_tgt)\n",
        "loss, loss.shape, shifted_tgt"
      ],
      "metadata": {
        "id": "WgvICWU0Wg0j",
        "outputId": "07da1b70-660d-44b1-acdb-2cf0edcd84cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WgvICWU0Wg0j",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(10.3868, grad_fn=<NegBackward0>),\n",
              " torch.Size([]),\n",
              " tensor([[  76,   10,  746,  810,  906,  335,  412, 2590,   17,    3]]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ffb21b",
      "metadata": {
        "id": "13ffb21b"
      },
      "source": [
        "## Define Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "64a3758c",
      "metadata": {
        "id": "64a3758c"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self, model, optimizer, loss_fn, train_loader, valid_loader, device):\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "    self.train_loader = train_loader\n",
        "    self.valid_loader = valid_loader\n",
        "    \n",
        "    self.model.to(device)\n",
        "    \n",
        "    self.best_valid_accuracy = 0\n",
        "    self.device = device\n",
        "    \n",
        "    self.training_loss = []\n",
        "    self.validation_loss = []\n",
        "    self.validation_acc = []\n",
        "\n",
        "  def save_model(self, path='kor_eng_translator_model.pt'):\n",
        "    torch.save({'model':self.model.state_dict(), 'optim':self.optimizer.state_dict()}, path)\n",
        "    \n",
        "  def train_by_num_epoch(self, num_epochs):\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "      self.model.train()\n",
        "      for batch in tqdm(self.train_loader, leave=False):\n",
        "        loss_value = self._train_by_single_batch(batch)\n",
        "        self.training_loss.append(loss_value)\n",
        "      self.model.eval()\n",
        "      validation_loss, validation_acc = self.validate()\n",
        "      self.validation_loss.append(validation_loss)\n",
        "      self.validation_acc.append(validation_acc)\n",
        "      \n",
        "      if validation_acc > self.best_valid_accuracy:\n",
        "        print(f\"Saving the model with best validation accuracy: Epoch {epoch+1}, Acc: {validation_acc:.4f} \")\n",
        "        self.save_model('kor_eng_translator_model_best.pt')\n",
        "      else:\n",
        "        self.save_model('kor_eng_translator_model_last.pt')\n",
        "      self.best_valid_accuracy = max(validation_acc, self.best_valid_accuracy)\n",
        "\n",
        "      \n",
        "  def _train_by_single_batch(self, batch):\n",
        "    '''\n",
        "    This method updates self.model's parameter with a given batch\n",
        "    \n",
        "    batch (tuple): (batch_of_input_text, batch_of_label)\n",
        "    \n",
        "    You have to use variables below:\n",
        "    \n",
        "    self.model (SentimentModel/torch.nn.Module): A neural network model\n",
        "    self.optimizer (torch.optim.adam.Adam): Adam optimizer that optimizes model's parameter\n",
        "    self.loss_fn (function): function for calculating BCE loss for a given prediction and target\n",
        "    self.device (str): 'cuda' or 'cpu'\n",
        "\n",
        "    output: loss (float): Mean binary cross entropy value for every sample in the training batch\n",
        "    The model's parameters, optimizer's steps has to be updated inside this method\n",
        "\n",
        "    TODO: Complete this method \n",
        "    '''\n",
        "    src, tgt, shifted_tgt = batch\n",
        "    src = src.to(self.device)\n",
        "    tgt = tgt.to(self.device)\n",
        "    shifted_tgt = shifted_tgt.to(self.device)\n",
        "\n",
        "    logit = self.model(src, tgt)\n",
        "    prob = logit.softmax(dim=-1)\n",
        "\n",
        "    loss = self.loss_fn(prob, shifted_tgt)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    self.optimizer.zero_grad\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "    \n",
        "  def validate(self, external_loader=None):\n",
        "    '''\n",
        "    This method calculates accuracy and loss for given data loader.\n",
        "    It can be used for validation step, or to get test set result\n",
        "    \n",
        "    input:\n",
        "      data_loader: If there is no data_loader given, use self.valid_loader as default.\n",
        "      \n",
        "    \n",
        "    output: \n",
        "      validation_loss (float): Mean Binary Cross Entropy value for every sample in validation set\n",
        "      validation_accuracy (float): Mean Accuracy value for every sample in validation set\n",
        "      \n",
        "    TODO: Complete this method \n",
        "\n",
        "    '''\n",
        "    \n",
        "    ### Don't change this part\n",
        "    if external_loader and isinstance(external_loader, DataLoader):\n",
        "      loader = external_loader\n",
        "      print('An arbitrary loader is used instead of Validation loader')\n",
        "    else:\n",
        "      loader = self.valid_loader\n",
        "      \n",
        "    self.model.eval()\n",
        "    \n",
        "    '''\n",
        "    Write your code from here, using loader, self.model, self.loss_fn.\n",
        "    '''\n",
        "\n",
        "hidden_size = 128\n",
        "model = Seq2seq(tokenizer_src.vocab_size, tokenizer_tgt.vocab_size, hidden_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nll_loss\n",
        "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=1, shuffle=True)\n",
        "device = 'cuda'\n",
        "\n",
        "trainer = Trainer(model, optimizer, loss_fn, train_loader, valid_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_records = []\n",
        "\n",
        "for i in range(100):\n",
        "  loss = trainer._train_by_single_batch(batch)\n",
        "  loss_records.append(loss)\n",
        "print(loss_records)"
      ],
      "metadata": {
        "id": "-zNWE0znYwwf",
        "outputId": "06c9a0c2-c5b5-43a7-ed71-fcd4b5caa521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-zNWE0znYwwf",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.193534851074219, 10.02066707611084, 9.846354484558105, 9.66327953338623, 9.464709281921387, 9.245087623596191, 9.001275062561035, 8.733030319213867, 8.44340991973877, 8.138773918151855, 7.827672481536865, 7.518471717834473, 7.217097759246826, 6.926039218902588, 6.644896030426025, 6.371555328369141, 6.103309154510498, 5.837619781494141, 5.572554111480713, 5.306925296783447, 5.040260314941406, 4.772683620452881, 4.504769325256348, 4.237377166748047, 3.971571683883667, 3.7086212635040283, 3.4500558376312256, 3.197673797607422, 2.953484058380127, 2.7196459770202637, 2.498401403427124, 2.2919318675994873, 2.1020638942718506, 1.9298683404922485, 1.775424838066101, 1.6379302740097046, 1.516051173210144, 1.408289909362793, 1.3132412433624268, 1.229710578918457, 1.1566909551620483, 1.0932362079620361, 1.0383795499801636, 0.9911945462226868, 0.9509075284004211, 0.9169001579284668, 0.8885766863822937, 0.865222156047821, 0.8459278345108032, 0.8296188712120056, 0.8152658343315125, 0.8020841479301453, 0.7895251512527466, 0.7772135138511658, 0.7649886012077332, 0.7528722286224365, 0.7409106492996216, 0.7290353178977966, 0.7170340418815613, 0.7045690417289734, 0.6912474632263184, 0.6767007112503052, 0.6606733202934265, 0.6430934071540833, 0.6240946650505066, 0.603999137878418, 0.5832909941673279, 0.5625914931297302, 0.5425897240638733, 0.5238092541694641, 0.5062946081161499, 0.4897615611553192, 0.47419795393943787, 0.46019265055656433, 0.4482335150241852, 0.43798428773880005, 0.42871615290641785, 0.41993090510368347, 0.4114615023136139, 0.40334877371788025, 0.3957293629646301, 0.3887381851673126, 0.38242611289024353, 0.37673842906951904, 0.37157267332077026, 0.3668360710144043, 0.3624736964702606, 0.3584549129009247, 0.35475897789001465, 0.3513413369655609, 0.3481181859970093, 0.34496375918388367, 0.3417404592037201, 0.33831986784935, 0.3345959186553955, 0.3304869830608368, 0.32592737674713135, 0.32086488604545593, 0.31526580452919006, 0.30912163853645325]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train_by_num_epoch(1)"
      ],
      "metadata": {
        "id": "mQx4K_3DZS-I",
        "outputId": "efdf1f48-9588-49c3-9b80-c6e4a1cdb54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7e0c64845c244720b529a238fb7f03fc",
            "2ce4571ca8c3486db82cf5111b49b979",
            "d01cea5d86be431fa519656159469c88",
            "50f476d7d8e84e8a81539a9a3549c1d4",
            "601a23ba484145af8eec1946779a53d8",
            "0eb7936f98394185a72a8eb807798fe4",
            "4f4102090d5d4f079c0a23a218648049",
            "87be8f11d7304eea98f48b2f49448a24",
            "e718ea3aae714c89aaee1f1f79374cab",
            "4d0a96248ad549d6989d9cc4a58bc10f",
            "ccdb06e71d874d1f8210776f1f74ea28",
            "5daec47eff3040788002690b9d9ff559",
            "fa45e83d15cb442fb7890f9ccedac956",
            "a1f02abecc824b7b9f94ba2546ea7041",
            "3e01a4e4ef104f42a255d072e865d0ec",
            "496ec14697464ddf922fb72560efeabc",
            "bb4843917abc42d68b3df2fbb3d90519",
            "29011e908581492ebcb84b39c77fcc06",
            "91e2fea28b8e4386903bd5dbd39c9a2f",
            "f63757eee857429c83bf8bba81a36ff6",
            "c202c1da2c3549b1b759e9bc8609ffcd",
            "11f296f0327c43378b8e2cca2ac83ce8"
          ]
        }
      },
      "id": "mQx4K_3DZS-I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e0c64845c244720b529a238fb7f03fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/160000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5daec47eff3040788002690b9d9ff559"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e0c64845c244720b529a238fb7f03fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ce4571ca8c3486db82cf5111b49b979",
              "IPY_MODEL_d01cea5d86be431fa519656159469c88",
              "IPY_MODEL_50f476d7d8e84e8a81539a9a3549c1d4"
            ],
            "layout": "IPY_MODEL_601a23ba484145af8eec1946779a53d8"
          }
        },
        "2ce4571ca8c3486db82cf5111b49b979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eb7936f98394185a72a8eb807798fe4",
            "placeholder": "​",
            "style": "IPY_MODEL_4f4102090d5d4f079c0a23a218648049",
            "value": "  0%"
          }
        },
        "d01cea5d86be431fa519656159469c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87be8f11d7304eea98f48b2f49448a24",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e718ea3aae714c89aaee1f1f79374cab",
            "value": 0
          }
        },
        "50f476d7d8e84e8a81539a9a3549c1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d0a96248ad549d6989d9cc4a58bc10f",
            "placeholder": "​",
            "style": "IPY_MODEL_ccdb06e71d874d1f8210776f1f74ea28",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "601a23ba484145af8eec1946779a53d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb7936f98394185a72a8eb807798fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4102090d5d4f079c0a23a218648049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87be8f11d7304eea98f48b2f49448a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e718ea3aae714c89aaee1f1f79374cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d0a96248ad549d6989d9cc4a58bc10f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccdb06e71d874d1f8210776f1f74ea28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5daec47eff3040788002690b9d9ff559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa45e83d15cb442fb7890f9ccedac956",
              "IPY_MODEL_a1f02abecc824b7b9f94ba2546ea7041",
              "IPY_MODEL_3e01a4e4ef104f42a255d072e865d0ec"
            ],
            "layout": "IPY_MODEL_496ec14697464ddf922fb72560efeabc"
          }
        },
        "fa45e83d15cb442fb7890f9ccedac956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb4843917abc42d68b3df2fbb3d90519",
            "placeholder": "​",
            "style": "IPY_MODEL_29011e908581492ebcb84b39c77fcc06",
            "value": "  9%"
          }
        },
        "a1f02abecc824b7b9f94ba2546ea7041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e2fea28b8e4386903bd5dbd39c9a2f",
            "max": 160000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f63757eee857429c83bf8bba81a36ff6",
            "value": 14326
          }
        },
        "3e01a4e4ef104f42a255d072e865d0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c202c1da2c3549b1b759e9bc8609ffcd",
            "placeholder": "​",
            "style": "IPY_MODEL_11f296f0327c43378b8e2cca2ac83ce8",
            "value": " 14326/160000 [02:02&lt;19:28, 124.68it/s]"
          }
        },
        "496ec14697464ddf922fb72560efeabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb4843917abc42d68b3df2fbb3d90519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29011e908581492ebcb84b39c77fcc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e2fea28b8e4386903bd5dbd39c9a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f63757eee857429c83bf8bba81a36ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c202c1da2c3549b1b759e9bc8609ffcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f296f0327c43378b8e2cca2ac83ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}